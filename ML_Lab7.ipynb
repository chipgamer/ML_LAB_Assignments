{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e6cffe-fb23-4f89-8b24-49b703f364f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Perceptron Hyperparameters: {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 2000, 'alpha': 0.0001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP Hyperparameters: {'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50,), 'alpha': 10.0, 'activation': 'tanh'}\n",
      "Perceptron Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Answer       0.46      0.61      0.53        54\n",
      "    Question       0.94      0.50      0.65        60\n",
      "   Statement       0.41      0.48      0.44        58\n",
      "\n",
      "    accuracy                           0.53       172\n",
      "   macro avg       0.60      0.53      0.54       172\n",
      "weighted avg       0.61      0.53      0.54       172\n",
      "\n",
      "MLP Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Answer       0.58      0.61      0.59        54\n",
      "    Question       0.74      0.82      0.78        60\n",
      "   Statement       0.51      0.43      0.47        58\n",
      "\n",
      "    accuracy                           0.62       172\n",
      "   macro avg       0.61      0.62      0.61       172\n",
      "weighted avg       0.61      0.62      0.62       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Function to load data from Excel\n",
    "def load_data(text_file, tfidf_file):\n",
    "    # Load text and labels\n",
    "    text_data = pd.read_excel(text_file)\n",
    "    \n",
    "    # Load TF-IDF vectors\n",
    "    tfidf_data = pd.read_excel(tfidf_file)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X = tfidf_data.values  # TF-IDF vectors\n",
    "    y = text_data['Label'].values  # Labels (questions, answers, statements)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Function to perform hyperparameter tuning using RandomizedSearchCV\n",
    "def tune_hyperparameters_perceptron(X_train, y_train):\n",
    "    perceptron = Perceptron()\n",
    "    param_distributions = {\n",
    "        'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': np.logspace(-4, 1, 10),\n",
    "        'max_iter': [1000, 2000, 3000],\n",
    "        'tol': [1e-4, 1e-3, 1e-2],\n",
    "    }\n",
    "    search = RandomizedSearchCV(perceptron, param_distributions, n_iter=10, cv=5, random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    return search.best_estimator_, search.best_params_\n",
    "\n",
    "# Function to perform hyperparameter tuning for MLP\n",
    "def tune_hyperparameters_mlp(X_train, y_train):\n",
    "    mlp = MLPClassifier()\n",
    "    param_distributions = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50,50), (100,100)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': np.logspace(-5, 3, 5),\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "    }\n",
    "    search = RandomizedSearchCV(mlp, param_distributions, n_iter=10, cv=5, random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    return search.best_estimator_, search.best_params_\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset files\n",
    "    text_file = r\"D:\\ML\\Final Viva Text.xlsx\"  \n",
    "    tfidf_file = r\"D:\\ML\\tfidf_vectors.xlsx\"\n",
    "    \n",
    "    X, y = load_data(text_file, tfidf_file)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Tune hyperparameters for Perceptron\n",
    "    best_perceptron, best_perceptron_params = tune_hyperparameters_perceptron(X_train, y_train)\n",
    "    print(\"Best Perceptron Hyperparameters:\", best_perceptron_params)\n",
    "    \n",
    "    # Tune hyperparameters for MLP\n",
    "    best_mlp, best_mlp_params = tune_hyperparameters_mlp(X_train, y_train)\n",
    "    print(\"Best MLP Hyperparameters:\", best_mlp_params)\n",
    "    \n",
    "    # Evaluate the models on the test set\n",
    "    perceptron_predictions = best_perceptron.predict(X_test)\n",
    "    mlp_predictions = best_mlp.predict(X_test)\n",
    "    \n",
    "    print(\"Perceptron Classification Report:\\n\", classification_report(y_test, perceptron_predictions))\n",
    "    print(\"MLP Classification Report:\\n\", classification_report(y_test, mlp_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "684f4f6a-b25d-4d4a-9edb-8edd48a9d1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasic\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Classifier  Accuracy  Precision (Macro Avg)  Recall (Macro Avg)  \\\n",
      "0            SVM  0.593023               0.640211            0.591230   \n",
      "1  Decision Tree  0.569767               0.584325            0.570605   \n",
      "2  Random Forest  0.610465               0.611995            0.609919   \n",
      "3       AdaBoost  0.505814               0.550043            0.506556   \n",
      "4        XGBoost  0.622093               0.628632            0.622180   \n",
      "5       CatBoost  0.651163               0.659094            0.650532   \n",
      "6    Naive Bayes  0.296512               0.294907            0.294423   \n",
      "\n",
      "   F1-Score (Macro Avg)  \n",
      "0              0.600642  \n",
      "1              0.572082  \n",
      "2              0.607072  \n",
      "3              0.512152  \n",
      "4              0.623565  \n",
      "5              0.653048  \n",
      "6              0.293762  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Function to load data from Excel\n",
    "def load_data(text_file, tfidf_file):\n",
    "    # Load text and labels\n",
    "    text_data = pd.read_excel(text_file)\n",
    "    \n",
    "    # Load TF-IDF vectors\n",
    "    tfidf_data = pd.read_excel(tfidf_file)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X = tfidf_data.values  # TF-IDF vectors\n",
    "    y = text_data['Label'].values  # Labels (questions, answers, statements)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Function to encode labels into numerical form\n",
    "def encode_labels(y):\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)  # Convert labels like 'Question', 'Answer', 'Statement' into numeric values\n",
    "    return y_encoded, le\n",
    "\n",
    "# Function to evaluate classifiers and collect results\n",
    "def evaluate_classifiers(X_train, X_test, y_train, y_test):\n",
    "    classifiers = {\n",
    "        'SVM': SVC(),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'AdaBoost': AdaBoostClassifier(),\n",
    "        'XGBoost': xgb.XGBClassifier(),\n",
    "        'CatBoost': cb.CatBoostClassifier(verbose=0),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        class_report = classification_report(y_test, predictions, output_dict=True)\n",
    "        \n",
    "        results.append({\n",
    "            'Classifier': name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision (Macro Avg)': class_report['macro avg']['precision'],\n",
    "            'Recall (Macro Avg)': class_report['macro avg']['recall'],\n",
    "            'F1-Score (Macro Avg)': class_report['macro avg']['f1-score']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset files\n",
    "    text_file = r\"D:\\ML\\Final Viva Text.xlsx\"  \n",
    "    tfidf_file = r\"D:\\ML\\tfidf_vectors.xlsx\"\n",
    "    \n",
    "    X, y = load_data(text_file, tfidf_file)\n",
    "\n",
    "    # Encode labels (e.g., 'Question' -> 0, 'Answer' -> 1, 'Statement' -> 2)\n",
    "    y_encoded, label_encoder = encode_labels(y)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Evaluate classifiers and tabulate results\n",
    "    results_df = evaluate_classifiers(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Display the tabulated results\n",
    "    print(results_df)\n",
    "\n",
    "    # Optional: Decode the predicted labels back to original form if necessary\n",
    "    # predicted_labels = label_encoder.inverse_transform(predicted_numeric_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc218a10-c7c5-428a-a535-3d116ce5f422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
